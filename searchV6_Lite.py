import streamlit as st
import pandas as pd
import sqlite3
import io
from datetime import datetime

# === è³‡æ–™åº«é€£ç·š ===
sqlite3.connect('mydb.sqlite', check_same_thread=False)

st.title("ğŸ” ä¼æ¥­å±¥æ­·ç¶œåˆæŸ¥è©¢å·¥å…·")

# --- æŸ¥è©¢æ¢ä»¶è¼¸å…¥ ---
company_id_input = st.text_input("å…¬å¸çµ±ç·¨", "")
company_name_input = st.text_input("å…¬å¸åç¨±", "")

years_sql = """
    SELECT DISTINCT apply_year FROM rd_project
    UNION
    SELECT DISTINCT apply_year FROM smart_project
"""
years = pd.read_sql(years_sql, conn)
year_options = sorted(years['apply_year'].dropna().unique(), reverse=True)
selected_year = st.selectbox("ç”³è«‹å¹´åº¦", options=[None] + list(year_options))
group_options = ['æ–°èˆˆè·¨åŸŸçµ„', 'å¹³å°ç¶“æ¿Ÿçµ„', 'æ•¸ä½æœå‹™çµ„', 'é€šè¨Šå‚³æ’­çµ„']
selected_group = st.selectbox("çµ„åˆ¥ç¯©é¸", options=[None] + group_options)

# --- session_state åˆå§‹åŒ– ---
if 'dfs' not in st.session_state:
    st.session_state['dfs'] = []

# --- é–‹å§‹æŸ¥è©¢æŒ‰éˆ•è§¸ç™¼ ---
if st.button("é–‹å§‹æŸ¥è©¢"):
    st.session_state['dfs'] = []  # æ¸…ç©ºèˆŠçµæœ

    # é¡¯ç¤ºæŸ¥è©¢æ¢ä»¶
    st.write("ğŸ¯ æŸ¥è©¢æ¢ä»¶")
    st.write(f"å…¬å¸çµ±ç·¨ï¼š{company_id_input or 'ï¼ˆæœªå¡«ï¼‰'}")
    st.write(f"å…¬å¸åç¨±ï¼š{company_name_input or 'ï¼ˆæœªå¡«ï¼‰'}")
    st.write(f"ç”³è«‹å¹´åº¦ï¼š{selected_year or 'ï¼ˆæœªé¸ï¼‰'}")
    st.write(f"æ”¶æ¡ˆçµ„åˆ¥ï¼š{selected_group or 'ï¼ˆæœªå¡«ï¼‰'}")

    # --- ç¯©é¸ helper å‡½å¼ ---
    def make_filter(table_alias, field, use_group=False, name_field="project_name"):
        clause = ""
        if company_name_input:
             clause += f" AND {table_alias}.company_name LIKE '%{company_name_input}%'"
        elif company_id_input:
            clause += f" AND {table_alias}.{field} = '{company_id_input}'"
        if selected_year:
            clause += f" AND {table_alias}.apply_year = {selected_year}"
        if use_group and selected_group:
            clause += f" AND trim({table_alias}.\"group\") = '{selected_group}'"
        return clause
    # --- ç ”ç™¼è³‡æ–™ ---
    rd_query = """
        SELECT a.*, b.apply_amount, b.approved
        FROM rd_project AS a
        LEFT JOIN rd_item AS b
        ON a.apply_year = b.apply_year
           AND a.company_id = b.company_id
           AND a.project_name = b.project_name
        WHERE 1=1
    """
    rd_query += make_filter('a', 'company_id', use_group=True,name_field='project_name')

    rd_df = pd.read_sql(rd_query, conn)

    # æ”¹ä¸­æ–‡æ¬„ä½
    rd_df = rd_df.rename(columns={
        "company_id": "å…¬å¸çµ±ç·¨",
        "company_name": "å…¬å¸åç¨±",
        "apply_year": "ç”³è«‹å¹´åº¦",
        "project_name": "è¨ˆç•«åç¨±",
        "group": "æ”¶æ¡ˆçµ„åˆ¥",
        "type_innovation_sme": "ç”¢å‰µ/ä¸­å°ä¼",
        "industry_category": "ç”¢æ¥­é¡åˆ¥",
        "apply_amount": "ç”³è«‹é‡‘é¡",
        "approved": "æ˜¯å¦é€šé"
    })
    #å„€è¡¨æ¿åŠŸèƒ½
    if not rd_df.empty and "ç”³è«‹é‡‘é¡" in rd_df.columns and "æ˜¯å¦é€šé" in rd_df.columns:
        rd_df["ç”³è«‹é‡‘é¡"] = pd.to_numeric(rd_df["ç”³è«‹é‡‘é¡"], errors="coerce")

        total_cases_rd = len(rd_df)
        total_amount_rd = rd_df["ç”³è«‹é‡‘é¡"].sum()

        approved_df_rd = rd_df[rd_df["æ˜¯å¦é€šé"] == "é€šé"]
        approved_cases_rd = len(approved_df_rd)
        approved_amount_rd = approved_df_rd["ç”³è«‹é‡‘é¡"].sum()

        case_rate_rd = f"{(approved_cases_rd / total_cases_rd * 100):.1f}%" if total_cases_rd > 0 else "0%"
        amount_rate_rd = f"{(approved_amount_rd / total_amount_rd * 100):.1f}%" if total_amount_rd > 0 else "0%"

        st.markdown("### ç ”ç™¼æŠ•æŠµ çµ±è¨ˆæ‘˜è¦")
        # ç¬¬ä¸€æ’
        col1, col2 = st.columns(2)
        col1.metric("ç¸½ä»¶æ•¸", total_cases_rd)
        col2.metric("ç”³è«‹é‡‘é¡ç¸½é¡", f"{total_amount_rd:,.0f}å…ƒ")

        # ç¬¬äºŒæ’
        col3, col4 = st.columns(2)
        col3.metric("é€šéä»¶æ•¸", approved_cases_rd)
        col4.metric("é€šéé‡‘é¡", f"{approved_amount_rd:,.0f}å…ƒ")

        # ç¬¬ä¸‰æ’
        col5, col6 = st.columns(2)
        col5.metric("æ¡ˆä»¶é€šéç‡", case_rate_rd)
        col6.metric("é‡‘é¡é€šéç‡", amount_rate_rd)
    #å±•ç¤ºç ”ç™¼è³‡æ–™
    st.subheader("ğŸ§ª ç ”ç™¼è³‡æ–™")
    st.dataframe(rd_df)
    st.session_state['dfs'].append(('ç ”ç™¼è³‡æ–™', rd_df))

    # --- è¨­å‚™è³‡æ–™ ---
    smart_query = """
        SELECT a.*, b.item_no, b.item_name, b.item_type, b.total_amount, b.subsidy, b.apply_amount, b.first_review, b.final_review
        FROM smart_project AS a
        LEFT JOIN smart_item AS b
        ON a.apply_year = b.apply_year
           AND a.company_id = b.company_id
           AND a.plan_name = b.plan_name
        WHERE 1=1
    """
    smart_query += make_filter('a', 'company_id',name_field='plan_name')

    raw_smart = pd.read_sql(smart_query, conn)

    mapping = {
        'è³‡å®‰ç”¢æ¥­': 'æ–°èˆˆè·¨åŸŸçµ„',
        **dict.fromkeys([
            'å…¶ä»–ç„¡åº—é¢é›¶å”®æ¥­-é›»å­è³¼ç‰©','å…¶ä»–ç„¡åº—é¢é›¶å”®æ¥­-ç¬¬ä¸‰æ–¹æ”¯ä»˜',
            'è»Ÿé«”å‡ºç‰ˆæ¥­-ç·šä¸ŠéŠæˆ²','è³‡è¨Šæœå‹™æ¥­-é›»ç°½æœå‹™','è»Ÿé«”å‡ºç‰ˆæ¥­-æ•¸ä½å…§å®¹'
        ], 'å¹³å°ç¶“æ¿Ÿçµ„'),
        **dict.fromkeys([
            'è»Ÿé«”å‡ºç‰ˆæ¥­-å¥—è£è»Ÿé«”','é›»è…¦ç¨‹å¼è¨­è¨ˆã€è«®è©¢ç›¸é—œæœå‹™æ¥­','è³‡è¨Šæœå‹™æ¥­','è³‡è¨Šæœå‹™ç”¢æ¥­'
        ], 'æ•¸ä½æœå‹™çµ„'),
        **dict.fromkeys(['é›»ä¿¡ç”¢æ¥­','å‚³æ’­äº‹æ¥­'], 'é€šè¨Šå‚³æ’­çµ„')
    }
    raw_smart['mapped_group'] = raw_smart['industry_category'].map(mapping)

    if selected_group:
        smart_df = raw_smart[raw_smart['mapped_group'] == selected_group]
    else:
        smart_df = raw_smart.copy()
    
    smart_df = smart_df.rename(columns={
        "company_id": "å…¬å¸çµ±ç·¨",
        "company_name": "å…¬å¸åç¨±",
        "apply_year": "ç”³è«‹å¹´åº¦",
        "plan_name": "è¨ˆç•«åç¨±",
        "mapped_group": "æ”¶æ¡ˆçµ„åˆ¥",
        "industry_category": "ç”¢æ¥­é¡åˆ¥",
        "item_no": "é …ç›®ç·¨è™Ÿ",
        "item_name": "é …ç›®åç¨±",
        "item_type": "é …ç›®é¡å‹",
        "total_amount": "è³¼è²·ç¸½é‡‘é¡",
        "subsidy": "è£œåŠ©æ¬¾",
        "apply_amount": "ç”³è«‹é‡‘é¡",
        "first_review": "åˆå¯©çµæœ",
        "final_review": "è¤‡å¯©çµæœ"
    })
    if not smart_df.empty and "ç”³è«‹é‡‘é¡" in smart_df.columns and "è¤‡å¯©çµæœ" in smart_df.columns:
        smart_df["ç”³è«‹é‡‘é¡"] = pd.to_numeric(smart_df["ç”³è«‹é‡‘é¡"], errors="coerce")

        total_cases_s = len(smart_df)
        total_amount_s = smart_df["ç”³è«‹é‡‘é¡"].sum()

        approved_df_s = smart_df[smart_df["è¤‡å¯©çµæœ"] == "è¤‡å¯©é …ç›®æ ¸å®š"]
        approved_cases_s = len(approved_df_s)
        approved_amount_s = approved_df_s["ç”³è«‹é‡‘é¡"].sum()

        case_rate_s = f"{(approved_cases_s / total_cases_s * 100):.1f}%" if total_cases_s > 0 else "0%"
        amount_rate_s = f"{(approved_amount_s / total_amount_s * 100):.1f}%" if total_amount_s > 0 else "0%"
        
        with st.container():
            # è¨­å‚™æŠ•æŠµ çµ±è¨ˆæ‘˜è¦
            st.markdown("### è¨­å‚™æŠ•æŠµ çµ±è¨ˆæ‘˜è¦")
            col1, col2 = st.columns(2)
            col1.metric("é …ç›®æ•¸", total_cases_s)
            col2.metric("ç”³è«‹é‡‘é¡ç¸½é¡", f"{total_amount_s:,.0f}å…ƒ")

            col3, col4 = st.columns(2)
            col3.metric("é€šéé …ç›®æ•¸", approved_cases_s)
            col4.metric("é€šéé‡‘é¡", f"{approved_amount_s:,.0f}å…ƒ")

            col5, col6 = st.columns(2)
            col5.metric("é …ç›®é€šéç‡", case_rate_s)
            col6.metric("é‡‘é¡é€šéç‡", amount_rate_s)


    st.subheader("ğŸ¤– è¨­å‚™æŠ•æŠµè³‡æ–™")
    st.dataframe(smart_df)
    st.session_state['dfs'].append(('è¨­å‚™è³‡æ–™', smart_df))

    # --- ä¸Šå¸‚æ«ƒè³‡æ–™ ---
    ipo_query = "SELECT * FROM ipo_info WHERE 1=1"
    if company_name_input:
        ipo_query += f" AND company_name LIKE '%{company_name_input}%'"
    elif company_id_input:
        ipo_query += f" AND company_id = '{company_id_input}'"
    if selected_group:
        ipo_query += f" AND trim(\"group\") = '{selected_group}'"

    ipo_df = pd.read_sql(ipo_query, conn)
    # æ—¥æœŸè½‰æ°‘åœ‹å¹´ #è½‰ä¸­æ–‡æ¬„ä½
    ipo_df = ipo_df.rename(columns={
        "company_id": "å…¬å¸çµ±ç·¨",
        "company_name": "å…¬å¸åç¨±",
        "capital": "å¯¦æ”¶è³‡æœ¬é¡",
        "apply_date": "ç”³è«‹æ—¥æœŸ",
        "visit_date": "æ‹œæœƒæ—¥æœŸ",
        "meeting_date": "è©•ä¼°æœƒè­°æ—¥æœŸ",
        "ipo_type": "ä¸Šå¸‚æ«ƒé¡å‹",
        "group": "æ¥­å‹™çµ„åˆ¥",
        "country": "åœ‹å…§/åœ‹å¤–",
        "broker": "ä¸»è¾¦åˆ¸å•†",
        "status": "æ‹œæœƒæ™‚ç‹€æ…‹",
        "result": "ç”³è«‹çµæœ",
        "remark": "çµæœå‚™è¨»"
    })
    # --- æ—¥æœŸè½‰æ°‘åœ‹å¹´ ---
    def to_roc_str(dt):
        if pd.isnull(dt):
            return ""
        roc_year = dt.year - 1911
        return f"{roc_year}/{dt.month}/{dt.day}"
    if "ç”³è«‹æ—¥æœŸ" in ipo_df.columns:
        ipo_df["ç”³è«‹æ—¥æœŸ"] = pd.to_datetime(ipo_df["ç”³è«‹æ—¥æœŸ"], errors='coerce').apply(to_roc_str)
    if "æ‹œæœƒæ—¥æœŸ" in ipo_df.columns:
        ipo_df["æ‹œæœƒæ—¥æœŸ"] = pd.to_datetime(ipo_df["æ‹œæœƒæ—¥æœŸ"], errors='coerce').apply(to_roc_str)
    if "è©•ä¼°æœƒè­°æ—¥æœŸ" in ipo_df.columns:
        ipo_df["è©•ä¼°æœƒè­°æ—¥æœŸ"] = pd.to_datetime(ipo_df["è©•ä¼°æœƒè­°æ—¥æœŸ"], errors='coerce').apply(to_roc_str)

    if not ipo_df.empty:
        st.subheader("ğŸ“ˆ ä¸Šå¸‚æ«ƒè³‡æ–™")
        st.dataframe(ipo_df)
        st.session_state['dfs'].append(('ä¸Šå¸‚æ«ƒè³‡æ–™', ipo_df))
    else:
        st.info("â„¹ï¸ ç„¡ç¬¦åˆæ¢ä»¶çš„ä¸Šå¸‚æ«ƒè³‡æ–™")

# --- ä¸‹è¼‰æŒ‰éˆ• ---
if st.session_state['dfs']:
    company_label = company_id_input or (company_name_input or 'ALL')
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"æŸ¥è©¢çµæœ_{company_label}_{selected_year or 'ALL'}_{timestamp}.xlsx"

    buffer = io.BytesIO()
    with pd.ExcelWriter(buffer, engine='openpyxl') as writer:
        for name, df in st.session_state['dfs']:
            df.to_excel(writer, sheet_name=name[:31], index=False)
    buffer.seek(0)

    st.download_button(
        label="ğŸ“¥ ä¸‹è¼‰æŸ¥è©¢çµæœ Excel",
        data=buffer,
        file_name=filename,
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )

# é—œé–‰
conn.close()
